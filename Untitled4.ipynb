{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chijiro31/-Infinite-Feature-Selection-a-Graph-based-Feature-/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf_UQvHGM5QT"
      },
      "source": [
        "# **Infinite Feature Selection: A Graph-based Feature Filtering Approach**\n",
        "\n",
        "*  Giorgio Roffo, Simone Melzi, Member, IEEE, Umberto Castellani,\n",
        " Alessandro Vinciarelli, Member, IEEE and Marco Cristani, Member, IEEE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbaThFFtagOs"
      },
      "source": [
        "**Improtar las Bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_LZi9BqN4FN"
      },
      "outputs": [],
      "source": [
        "!pip install skrebate gdown\n",
        "!git clone https://github.com/jundongl/scikit-feature.git\n",
        "!pip install scikit-learn skrebate sklearn-feature-selection\n",
        "\n",
        "%cd scikit-feature\n",
        "!pip install -e .\n",
        "!pip install -e .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sju2sd3Rarf5"
      },
      "source": [
        "**Configuraci√≥n de visualizaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAWqP0ELVpZz"
      },
      "outputs": [],
      "source": [
        "plt.style.use('ggplot')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qjVIfyMaxvJ"
      },
      "source": [
        "**Cargar el archivo CSV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7mS5zFDa00L"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrD09NVNa7Bo"
      },
      "source": [
        "**Leer los Datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtCOyZ0FbCqm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Cargar archivos\n",
        "X_train = np.loadtxt(\"X_train.txt\")\n",
        "y_train = np.loadtxt(\"y_train.txt\")\n",
        "X_test = np.loadtxt(\"X_test.txt\")\n",
        "y_test = np.loadtxt(\"y_test.txt\")\n",
        "\n",
        "# Combinar todo\n",
        "X = np.vstack([X_train, X_test])\n",
        "y = np.hstack([y_train, y_test])\n",
        "\n",
        "# Escalar\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp7Eypf92Y-b"
      },
      "source": [
        "# **1. Metodos de Filtrado**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJEDOcth2gMD"
      },
      "source": [
        "# **No supervisado**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghicU7moi4bd"
      },
      "source": [
        "**Laplacian Score (LS)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2spEKpeh2fuq",
        "outputId": "6bcd1d02-4648-44d8-87d9-62b7b48ffb06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 features (Laplacian Score): [550 402 388 416 337 481 524 554 555 467 323 379 238 495 309 380 377 557\n",
            " 194 448]\n"
          ]
        }
      ],
      "source": [
        "from skfeature.function.similarity_based import lap_score\n",
        "from skfeature.utility import construct_W\n",
        "W = construct_W.construct_W(X_scaled)\n",
        "scores = lap_score.lap_score(X_scaled, W=W)\n",
        "lap_ranking = np.argsort(scores)[::-1]\n",
        "print(\"Top 20 features (Laplacian Score):\", lap_ranking[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e7lS2YIi-ch"
      },
      "source": [
        "**Multi-Cluster Feature Selection (MCFS)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THgZRnGfjAJg",
        "outputId": "b814d9cc-09fa-493f-c03d-8cf483891449"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.105e-06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from skfeature.function.sparse_learning_based import MCFS\n",
        "from sklearn.exceptions import *\n",
        "import warnings\n",
        "\n",
        "weight = MCFS.mcfs(X_scaled, n_selected_features=20, n_clusters=6)\n",
        "mcfs_ranking = np.argsort(np.abs(weight))[::-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf3227nLjCaQ"
      },
      "source": [
        "**Local Learning-based Clustering Feature Selection (LLCFS)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjuy68KL234x"
      },
      "source": [
        "# **Supervisados**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA0vgA_43DW6"
      },
      "source": [
        "**Relief-F**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfOvagYH3Ke7",
        "outputId": "cecaf67c-09b3-4af3-ea2f-c79f29c70606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 features (ReliefF): [366  56 287 367   9 523 234 368 102 510 558 288   3 280 271 268 231 226\n",
            " 265  95]\n"
          ]
        }
      ],
      "source": [
        "from skrebate import ReliefF\n",
        "import numpy as np\n",
        "\n",
        "# Inicializar rankings si a√∫n no existe\n",
        "rankings = {}\n",
        "\n",
        "r = ReliefF(n_neighbors=10)\n",
        "r.fit(X_scaled, y)\n",
        "\n",
        "# Guardar ranking\n",
        "rankings['ReliefF'] = np.argsort(r.feature_importances_)[::-1]\n",
        "print(\"Top 20 features (ReliefF):\", rankings['ReliefF'][:20])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfjioxzw3HbD"
      },
      "source": [
        "**Mutual Information (MI)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7g1vWp7_OH0",
        "outputId": "1e78bed7-038f-4f5d-f0d3-45fdc94c14e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 features (MI): [ 52  40  49  56 302 310 268   9 314   3 281  16 381 504 201 214 503 274\n",
            "   6 271]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "mi_scores = mutual_info_classif(X_scaled, y, random_state=42)\n",
        "mi_ranking = np.argsort(mi_scores)[::-1]\n",
        "rankings['Mutual Information'] = mi_ranking\n",
        "print(\"Top 20 features (MI):\", mi_ranking[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "763RZrKv3NTS"
      },
      "source": [
        "**Fisher Score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEEm2KXp3O3Z",
        "outputId": "c1d74c14-d7fb-4d3d-ffdc-d2b54ca7e3e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 features (Fisher Score): [381 389 393 382 303 360  96 386 391 310 314 281 302 385 232 383 394 390\n",
            " 397  16]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def fisher_score(X, y):\n",
        "    \"\"\"Fisher score\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X: {numpy array}, shape (n_samples, n_features)\n",
        "        input data\n",
        "    y: {numpy array}, shape (n_samples,)\n",
        "        input class labels\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    scores: {numpy array}, shape (n_features,)\n",
        "        fisher scores for each feature\n",
        "    \"\"\"\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "    unique_classes = np.unique(y)\n",
        "    n_classes = len(unique_classes)\n",
        "\n",
        "    # overall mean\n",
        "    mean_overall = np.mean(X, axis=0)\n",
        "    scores = np.zeros(n_features)\n",
        "\n",
        "    for c in unique_classes:\n",
        "        X_c = X[y == c]\n",
        "        n_c = X_c.shape[0]\n",
        "        mean_c = np.mean(X_c, axis=0)\n",
        "        var_c = np.var(X_c, axis=0) + 1e-12  # add epsilon to avoid div by 0\n",
        "\n",
        "        scores += (n_c * (mean_c - mean_overall) ** 2) / var_c\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "fs = fisher_score(X_scaled, y)\n",
        "ranking_fs = np.argsort(fs)[::-1]\n",
        "rankings['Fisher Score'] = ranking_fs\n",
        "\n",
        "print(\"Top 20 features (Fisher Score):\", ranking_fs[:20])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPCdkGlJ3R3J"
      },
      "source": [
        "**ECFS (Ensemble Approach), ILFS (Infinite Latent Feature Selection), Inf‚ÄëFS (no supervisado/supervisado)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Coyj_QrHIrpz",
        "outputId": "316c0f67-9a4e-4e66-bdc7-fdfb4fd2fb70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: PyIFS\n",
            "Version: 0.0.3\n",
            "Summary: A python3 package for infinite feature selection\n",
            "Home-page: https://https://github.com/InfOmics/PyIFS\n",
            "Author: nightwnvol\n",
            "Author-email: notte_94@hotmail.it\n",
            "License: UNKNOWN\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: numpy\n",
            "Required-by: \n",
            "import scipy.stats as stats\n",
            "import scipy.stats as stats\n",
            "import scipy.stats as stats\n",
            "import scipy.stats as stats\n",
            "# Infinite Feature Selection.\n",
            "\n",
            "# Inputs:\n",
            "#   x_train: matrix T (samples) by n (number of features).\n",
            "#   y_train: column vector of labels (-1,1).\n",
            "#   verbose: boolean variable.\n",
            "\n",
            "# Outputs:\n",
            "#   RANKED: vector of indicies of x_train from the best to the worst feature.\n",
            "\n",
            "import numpy as np\n",
            "\n",
            "class InfFS:\n",
            "\n",
            "    def __init__(self):\n",
            "        h=0.1\n",
            "        #print(\"HI\")\n",
            "    # Take in input the matrix e the label vector and return a matrix\n",
            "    # of data for every different label.\n",
            "    def takeLabel(self, x_train, y_train ):\n",
            "        counter = x_train.shape[0] -1\n",
            "        s_n = x_train\n",
            "        s_p = x_train\n",
            "        while(1):\n",
            "            if( y_train[counter] == 1 ):\n",
            "                s_n = np.delete(s_n, counter, axis = 0 )\n",
            "            else:\n",
            "                s_p = np.delete(s_p, counter, axis = 0 )\n",
            "            counter = counter - 1\n",
            "            if( counter == - 1 ):\n",
            "                break\n",
            "        return s_p, s_n\n",
            "\n",
            "    # Function that help to define priors_corr.\n",
            "    def defPriorsCorr(self,mu_s_n, mu_s_p):\n",
            "        pcorr = mu_s_p\n",
            "import scipy.stats as stats\n",
            "import scipy.stats as stats\n",
            "import scipy.stats as stats\n",
            "import scipy.stats as stats\n",
            "import scipy.stats as stats\n",
            "# Infinite Feature Selection.\n",
            "\n",
            "# Inputs:\n",
            "#   x_train: matrix T (samples) by n (number of features).\n",
            "#   y_train: column vector of labels (-1,1).\n",
            "#   verbose: boolean variable.\n",
            "\n",
            "# Outputs:\n",
            "#   RANKED: vector of indicies of x_train from the best to the worst feature.\n",
            "\n",
            "import numpy as np\n",
            "\n",
            "class InfFS:\n",
            "\n",
            "    def __init__(self):\n",
            "        h=0.1\n",
            "        #print(\"HI\")\n",
            "    # Take in input the matrix e the label vector and return a matrix\n",
            "    # of data for every different label.\n",
            "    def takeLabel(self, x_train, y_train ):\n",
            "        counter = x_train.shape[0] -1\n",
            "        s_n = x_train\n",
            "        s_p = x_train\n",
            "        while(1):\n",
            "            if( y_train[counter] == 1 ):\n",
            "                s_n = np.delete(s_n, counter, axis = 0 )\n",
            "            else:\n",
            "                s_p = np.delete(s_p, counter, axis = 0 )\n",
            "            counter = counter - 1\n",
            "            if( counter == - 1 ):\n",
            "                break\n",
            "        return s_p, s_n\n",
            "\n",
            "    # Function that help to define priors_corr.\n",
            "    def defPriorsCorr(self,mu_s_n, mu_s_p):\n"
          ]
        }
      ],
      "source": [
        "!pip show PyIFS\n",
        "# Abre el archivo con sed o nano para editarlo (si tienes permisos)\n",
        "!head -40 /usr/local/lib/python3.11/dist-packages/PyIFS/InfFS.py\n",
        "# Usa sed para insertar la l√≠nea al inicio del archivo:\n",
        "!sed -i '1i import scipy.stats as stats' /usr/local/lib/python3.11/dist-packages/PyIFS/InfFS.py\n",
        "!head -40 /usr/local/lib/python3.11/dist-packages/PyIFS/InfFS.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "JkHzYIeB3TLM",
        "outputId": "f224ec74-abe2-4b97-913d-78303e50d747"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'stats' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-b3dae8b54f02>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Inf‚ÄëFS no supervisado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrank_unsup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfFS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupervision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mrankings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Inf-FS(u)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank_unsup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top-20 Inf-FS(u):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_unsup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PyIFS/InfFS.py\u001b[0m in \u001b[0;36minfFS\u001b[0;34m(self, x_train, y_train, alpha, supervision, verbose)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mcorr_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpriors_corr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mcorr_ij\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr_ij\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mcorr_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcorr_ij\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr_ij\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mcorr_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubtractMin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
          ]
        }
      ],
      "source": [
        "from PyIFS import InfFS\n",
        "import scipy.stats as stats\n",
        "import importlib\n",
        "import PyIFS.InfFS\n",
        "\n",
        "inf = InfFS()\n",
        "\n",
        "# Inf‚ÄëFS no supervisado\n",
        "rank_unsup, _ = inf.infFS(X_scaled, None, alpha=0.5, supervision=0, verbose=0)\n",
        "rankings['Inf-FS(u)'] = rank_unsup\n",
        "print(\"Top-20 Inf-FS(u):\", rank_unsup[:20])\n",
        "\n",
        "rank_sup, _ = inf.infFS(X_scaled, y, alpha=0.5, supervision=1, verbose=0)\n",
        "rankings['Inf-FS(s)'] = rank_sup\n",
        "print(\"Top-20 Inf-FS(s):\", rank_sup[:20])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwG-lMUBC1Pz"
      },
      "source": [
        "# **2.Metodos de Envoltura**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdKZ3Xe3C7GO"
      },
      "source": [
        "**No Supervisado**\n",
        "\n",
        "1.   DGUFS\n",
        "2.   FSASL\n",
        "3. UFSOL\n",
        "\n",
        "**Supervisado**\n",
        "\n",
        "1.   RFE\n",
        "2.   SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5Ww7b0fRWdb",
        "outputId": "5981fdb9-0c8a-4fbc-c13c-09142fa64970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 0: residual norm = 129.4301\n",
            "Iter 10: residual norm = 147.6127\n",
            "Iter 20: residual norm = 114.2884\n",
            "Iter 30: residual norm = 131.0099\n",
            "Iter 40: residual norm = 124.4523\n",
            "Top‚Äë20 DGUFS: [173  94 174 172  93  92 133 132  14  12 134  52  68  40  13  49  66  56\n",
            "  76  74]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import normalize\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# üîπ 1. Definici√≥n del m√©todo dgufs\n",
        "def dgufs(X, n_clusters, n_features, max_iter=50, alpha=1.0, beta=1.0, verbose=False):\n",
        "    n_samples, d = X.shape\n",
        "\n",
        "    # Inicializar W y F\n",
        "    W = np.random.rand(d, n_clusters)\n",
        "    W = normalize(W, axis=0)\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
        "    F = kmeans.fit_transform(X)\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        # Actualizaci√≥n de F mediante clustering en X¬∑W\n",
        "        A = X @ W\n",
        "        kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
        "        F = kmeans.fit_transform(A)\n",
        "\n",
        "        # Actualizaci√≥n de W con esquema multiplicativo\n",
        "        numerator = X.T @ F\n",
        "        denominator = W @ (F.T @ F) + alpha * W + beta * np.sign(W)\n",
        "        W = W * (numerator / (denominator + 1e-10))\n",
        "        W = normalize(W, axis=0)\n",
        "\n",
        "        if verbose and i % 10 == 0:\n",
        "            print(f\"Iter {i}: residual norm = {norm(X @ W - F):.4f}\")\n",
        "\n",
        "    # Puntajes por fila de W y selecci√≥n de features\n",
        "    feature_scores = np.linalg.norm(W, axis=1)\n",
        "    selected = np.argsort(-feature_scores)[:n_features]\n",
        "    return selected, feature_scores\n",
        "\n",
        "# üîπ 2. Ejecutar DGUFS con tus datos\n",
        "n_clusters = len(np.unique(y))       # uno por clase (puedes ajustar)\n",
        "n_features = 20                      # n√∫mero de features a seleccionar\n",
        "\n",
        "selected_dgufs, scores_dgufs = dgufs(X_scaled, n_clusters, n_features, verbose=True)\n",
        "rankings['DGUFS'] = selected_dgufs\n",
        "print(\"Top‚Äë20 DGUFS:\", selected_dgufs[:20])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "573YZ0xUxFD8",
        "outputId": "937e055b-9ecd-4f74-8bf2-2bd7b0ac1f15"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'fsasl' from 'skfeature.function.sparse_learning_based' (/usr/local/lib/python3.11/dist-packages/skfeature/function/sparse_learning_based/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f088b1254ff1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# No Supervisado (FSASL)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_learning_based\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfsasl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mw_fsasl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsasl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsasl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_selected_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'fsasl' from 'skfeature.function.sparse_learning_based' (/usr/local/lib/python3.11/dist-packages/skfeature/function/sparse_learning_based/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# No Supervisado (FSASL)\n",
        "from skfeature.function.sparse_learning_based import fsasl\n",
        "import numpy as np\n",
        "\n",
        "w_fsasl = fsasl.fsasl(X_scaled, n_selected_features=20)\n",
        "\n",
        "# Suma pesos absolutos por caracter√≠stica\n",
        "fsasl_scores = np.sum(np.abs(w_fsasl), axis=1)\n",
        "\n",
        "# Ordenar de mayor a menor\n",
        "fsasl_ranking = np.argsort(fsasl_scores)[::-1]\n",
        "\n",
        "rankings['FSASL'] = fsasl_ranking\n",
        "\n",
        "print(\"Top 20 features (FSASL):\", fsasl_ranking[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHoKne08zBZB",
        "outputId": "5c87718d-e9a7-4a65-9ca1-81f47a68c0e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 features (UFSOL): [478 388 484 492 498 501 413 334 491 412 422 467 343 333 487 493 471 481\n",
            " 477 463]\n"
          ]
        }
      ],
      "source": [
        "# No Supervisado (UFSOL)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "from sklearn.preprocessing import normalize\n",
        "from scipy.sparse import csgraph\n",
        "\n",
        "def ufsol(X, n_features=20, sigma=1.0):\n",
        "    # construir matriz de afinidad W usando RBF\n",
        "    W = rbf_kernel(X, gamma=1 / (2 * sigma ** 2))\n",
        "    W = normalize(W, norm='l1', axis=1)\n",
        "\n",
        "    # calcular Laplaciano\n",
        "    L = csgraph.laplacian(W, normed=True)\n",
        "\n",
        "    # importancia de cada caracter√≠stica\n",
        "    scores = np.zeros(X.shape[1])\n",
        "    for i in range(X.shape[1]):\n",
        "        f = X[:, i]\n",
        "        scores[i] = f.T @ L @ f\n",
        "\n",
        "    # menor score = m√°s importante\n",
        "    ranking = np.argsort(scores)\n",
        "    return ranking\n",
        "\n",
        "ufsol_ranking = ufsol(X_scaled, n_features=20)\n",
        "rankings['UFSOL'] = ufsol_ranking\n",
        "print(\"Top 20 features (UFSOL):\", ufsol_ranking[:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nTOiyCHIuXjK"
      },
      "outputs": [],
      "source": [
        "# Supervisado (RFE)\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC(kernel='linear')\n",
        "rfe = RFE(svc, n_features_to_select=20).fit(X_scaled, y)\n",
        "rankings['RFE'] = np.argsort(rfe.ranking_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-2vscJb0yIaS"
      },
      "outputs": [],
      "source": [
        "# Supervisado (SVM)\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Entrena SVM lineal con L1 o L2\n",
        "svm = LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter=5000)\n",
        "svm.fit(X_scaled, y)\n",
        "\n",
        "# Ranking seg√∫n pesos\n",
        "fsv_scores = np.abs(svm.coef_).sum(axis=0)\n",
        "fsv_ranking = np.argsort(fsv_scores)[::-1]\n",
        "\n",
        "# Agregar a rankings\n",
        "rankings['FSV'] = fsv_ranking\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFMk2EpSRW37"
      },
      "source": [
        "# **3. Metodos Integrados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQW82nEbRdOa"
      },
      "source": [
        "**No Supervisado**\n",
        "\n",
        "1.   UDFS\n",
        "\n",
        "**Supervisado**\n",
        "\n",
        "1.   FSV\n",
        "2.   LASSO\n",
        "3. NHTP\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plWZg6-CR0Ly"
      },
      "outputs": [],
      "source": [
        "#No Supervisado (UDFS)\n",
        "\n",
        "from skfeature.function.sparse_learning_based import UDFS\n",
        "\n",
        "udfs_weight, _, _ = UDFS.udfs(X_scaled, n_clusters=6)\n",
        "udfs_ranking = np.argsort(np.sum(np.abs(udfs_weight), axis=1))[::-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJJWWi6_kdiQ"
      },
      "outputs": [],
      "source": [
        "#  Supervisado (LASSO / FSV)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lasso = LogisticRegression(penalty='l1', solver='liblinear').fit(X_scaled, y)\n",
        "lasso_ranking = np.argsort(np.abs(lasso.coef_).sum(axis=0))[::-1]\n",
        "#rankings['LASSO'] = np.argsort(np.abs(lasso.coef_).sum(axis=0))[::-1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMJMuSO2zkJZ"
      },
      "outputs": [],
      "source": [
        "# Supervisador (NHTP)\n",
        "\n",
        "def nhtp(X, y, k=20, max_iter=100, tol=1e-4):\n",
        "    n, d = X.shape\n",
        "    w = np.zeros(d)\n",
        "\n",
        "    for iteration in range(max_iter):\n",
        "        # Gradiente de la funci√≥n de p√©rdida (MSE)\n",
        "        gradient = -2 * X.T @ (y - X @ w)\n",
        "\n",
        "        # Paso de Newton (descenso)\n",
        "        w_temp = w - 0.01 * gradient\n",
        "\n",
        "        # Umbralizaci√≥n: mantener solo top-k entradas\n",
        "        idx = np.argsort(np.abs(w_temp))[-k:]\n",
        "        w_new = np.zeros(d)\n",
        "        w_new[idx] = w_temp[idx]\n",
        "\n",
        "        # Verificar convergencia\n",
        "        if np.linalg.norm(w_new - w) < tol:\n",
        "            break\n",
        "\n",
        "        w = w_new\n",
        "\n",
        "    # Ranking: ordenar por magnitud de coeficientes\n",
        "    ranking = np.argsort(np.abs(w))[::-1]\n",
        "    return ranking\n",
        "\n",
        "nhtp_ranking = nhtp(X_scaled, y, k=20)\n",
        "rankings['NHTP'] = nhtp_ranking\n",
        "print(\"Top 20 features (NHTP):\", nhtp_ranking[:20])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB-Jf8DWR0iS"
      },
      "source": [
        "# **Propuesta**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VN9Y6wtR5PX"
      },
      "source": [
        "**No supevisado**\n",
        "\n",
        "\n",
        "1.   Inf-FS (u)\n",
        "\n",
        "**Supervisado**\n",
        "1. Inf-FS (s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32kkzFG3YHrx"
      },
      "outputs": [],
      "source": [
        "from infFS import infFS  # Si ya clonaste el repo\n",
        "\n",
        "# No supervisado\n",
        "S_inf_unsup, _, _, _ = infFS(X_scaled, alpha=0.5, style='fs')\n",
        "inf_unsup_ranking = np.argsort(S_inf_unsup)[::-1]\n",
        "\n",
        "# Supervisado\n",
        "S_inf_sup, _, _, _ = infFS(X_scaled, alpha=0.5, style='supervised', Y=y)\n",
        "inf_sup_ranking = np.argsort(S_inf_sup)[::-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYI6lucWSMqh"
      },
      "source": [
        "# **Construccion de grafo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95fbKkRuSRnV"
      },
      "source": [
        "**1. Inf-FS (u)**\n",
        "\n",
        "\n",
        "**2. Inf-FS (s)**\n",
        "*   Fisher\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsMbzTxR783W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from skfeature.function.statistical_based import fisher_score\n",
        "\n",
        "# Usaremos X_scaled como datos normalizados\n",
        "\n",
        "# 1. Matriz de similitud entre caracter√≠sticas (usando cosine similarity)\n",
        "# similarity_matrix[i, j] = similitud entre feature_i y feature_j\n",
        "\n",
        "similarity_matrix = cosine_similarity(X_scaled.T)  # Transpuesta para comparar features\n",
        "\n",
        "# 2. Construcci√≥n del grafo con NetworkX\n",
        "G = nx.from_numpy_array(similarity_matrix)\n",
        "\n",
        "# Opcional: filtrar aristas con peso bajo para simplificar\n",
        "threshold = 0.5\n",
        "edges_to_remove = [(u, v) for u, v, w in G.edges(data='weight') if w < threshold]\n",
        "G.remove_edges_from(edges_to_remove)\n",
        "\n",
        "# 3. Visualizaci√≥n del grafo\n",
        "plt.figure(figsize=(10, 8))\n",
        "pos = nx.spring_layout(G, seed=42)  # Layout\n",
        "\n",
        "# Dibuja nodos con tama√±o proporcional a grado\n",
        "node_sizes = [1000 * G.degree(n) for n in G.nodes()]\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='skyblue', alpha=0.7)\n",
        "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "plt.title(\"Grafo de similitud entre caracter√≠sticas (Inf-FS no supervisado)\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9mz4NZ_8AAq"
      },
      "outputs": [],
      "source": [
        "# Calcular Fisher Score para ponderar\n",
        "fisher_scores = fisher_score(X_scaled, y)\n",
        "fisher_scores = fisher_scores / np.max(fisher_scores)  # Normalizar\n",
        "\n",
        "# Matriz de similitud b√°sica\n",
        "similarity_matrix_sup = cosine_similarity(X_scaled.T)\n",
        "\n",
        "# Ponderar por Fisher Score (ejemplo sencillo: producto)\n",
        "for i in range(similarity_matrix_sup.shape[0]):\n",
        "    for j in range(similarity_matrix_sup.shape[1]):\n",
        "        similarity_matrix_sup[i, j] *= (fisher_scores[i] + fisher_scores[j]) / 2\n",
        "\n",
        "# Construcci√≥n y visualizaci√≥n grafo supervisado similar al anterior\n",
        "G_sup = nx.from_numpy_array(similarity_matrix_sup)\n",
        "edges_to_remove = [(u, v) for u, v, w in G_sup.edges(data='weight') if w < threshold]\n",
        "G_sup.remove_edges_from(edges_to_remove)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "pos = nx.spring_layout(G_sup, seed=42)\n",
        "node_sizes = [1000 * G_sup.degree(n) for n in G_sup.nodes()]\n",
        "nx.draw_networkx_nodes(G_sup, pos, node_size=node_sizes, node_color='lightgreen', alpha=0.7)\n",
        "nx.draw_networkx_edges(G_sup, pos, alpha=0.5)\n",
        "nx.draw_networkx_labels(G_sup, pos, font_size=8)\n",
        "plt.title(\"Grafo de similitud entre caracter√≠sticas (Inf-FS supervisado)\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID-fS4w-8GD7"
      },
      "source": [
        "**Visualizaci√≥n del Fisher Score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRSzEiKV8ESU"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.bar(range(len(fisher_scores)), fisher_scores, color='orange')\n",
        "plt.title(\"Fisher Score por caracter√≠stica\")\n",
        "plt.xlabel(\"√çndice caracter√≠stica\")\n",
        "plt.ylabel(\"Puntaje Fisher normalizado\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9dgbSwEwL3D"
      },
      "source": [
        "# **VISUALIZACI√ìN Y EVALUACI√ìN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwLhoISt8c7y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from skfeature.function.statistical_based import fisher_score\n",
        "\n",
        "\n",
        "# --------------------------------------\n",
        "# 1. SIMILITUD ENTRE CARACTER√çSTICAS\n",
        "# --------------------------------------\n",
        "\n",
        "# Normalizar si no est√° hecho\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# X_scaled = MinMaxScaler().fit_transform(X)\n",
        "\n",
        "# Similitud entre caracter√≠sticas: cosine similarity (usado en Inf-FS)\n",
        "similarity_matrix_unsup = cosine_similarity(X_scaled.T)\n",
        "\n",
        "# --------------------------------------\n",
        "# 2. GRAFO NO SUPERVISADO (Inf-FS (u))\n",
        "# --------------------------------------\n",
        "G_unsup = nx.from_numpy_array(similarity_matrix_unsup)\n",
        "\n",
        "# Filtrado de aristas con bajo peso\n",
        "threshold = 0.5\n",
        "edges_to_remove = [(u, v) for u, v, w in G_unsup.edges(data='weight') if w < threshold]\n",
        "G_unsup.remove_edges_from(edges_to_remove)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "pos = nx.spring_layout(G_unsup, seed=42)\n",
        "nx.draw_networkx_nodes(G_unsup, pos, node_size=600, node_color='skyblue', alpha=0.7)\n",
        "nx.draw_networkx_edges(G_unsup, pos, alpha=0.4)\n",
        "nx.draw_networkx_labels(G_unsup, pos, font_size=7)\n",
        "plt.title(\"üîó Grafo de similitud entre caracter√≠sticas (Inf-FS No Supervisado)\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# --------------------------------------\n",
        "# 3. FISHER SCORE (para supervisi√≥n)\n",
        "# --------------------------------------\n",
        "fisher_scores = fisher_score(X_scaled, y)\n",
        "fisher_scores_norm = fisher_scores / np.max(fisher_scores)\n",
        "\n",
        "# --------------------------------------\n",
        "# 4. GRAFO SUPERVISADO (Inf-FS (s) con Fisher Score)\n",
        "# --------------------------------------\n",
        "similarity_matrix_sup = cosine_similarity(X_scaled.T)\n",
        "\n",
        "# Ponderar por Fisher\n",
        "for i in range(similarity_matrix_sup.shape[0]):\n",
        "    for j in range(similarity_matrix_sup.shape[1]):\n",
        "        similarity_matrix_sup[i, j] *= (fisher_scores_norm[i] + fisher_scores_norm[j]) / 2\n",
        "\n",
        "G_sup = nx.from_numpy_array(similarity_matrix_sup)\n",
        "edges_to_remove = [(u, v) for u, v, w in G_sup.edges(data='weight') if w < threshold]\n",
        "G_sup.remove_edges_from(edges_to_remove)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "pos = nx.spring_layout(G_sup, seed=42)\n",
        "nx.draw_networkx_nodes(G_sup, pos, node_size=600, node_color='lightgreen', alpha=0.7)\n",
        "nx.draw_networkx_edges(G_sup, pos, alpha=0.4)\n",
        "nx.draw_networkx_labels(G_sup, pos, font_size=7)\n",
        "plt.title(\"üß≠ Grafo de similitud (Inf-FS Supervisado con Fisher Score)\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# --------------------------------------\n",
        "# 5. VISUALIZACI√ìN DE RANKING: Fisher Score\n",
        "# --------------------------------------\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.bar(range(len(fisher_scores_norm)), fisher_scores_norm, color='orange')\n",
        "plt.title(\"üî• Fisher Score por caracter√≠stica (normalizado)\")\n",
        "plt.xlabel(\"√çndice de caracter√≠stica\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --------------------------------------\n",
        "# 6. INTEGRACI√ìN CON RANKINGS (si ya usaste Inf-FS)\n",
        "# --------------------------------------\n",
        "try:\n",
        "    print(\"üéØ Top 20 caracter√≠sticas (Inf-FS no supervisado):\", rankings['Inf-FS(u)'][:20])\n",
        "    print(\"üéØ Top 20 caracter√≠sticas (Inf-FS supervisado):\", rankings['Inf-FS(s)'][:20])\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Rankings no definidos todav√≠a en esta sesi√≥n:\", e)\n",
        "pd.DataFrame({k: v[:20] for k, v in rankings.items()}).to_csv(\"ranking_top20_todos.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB4KI-P7SaC_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "methods = list(rankings.keys())\n",
        "\n",
        "# Visual comparativa Top-20\n",
        "plt.figure(figsize=(12, 6))\n",
        "for name in methods:\n",
        "    top20 = rankings[name][:20]\n",
        "    plt.plot(top20, label=name)\n",
        "plt.legend()\n",
        "plt.title(\"Top-20 features por m√©todo\")\n",
        "plt.show()\n",
        "\n",
        "# Evaluaci√≥n por accuracy\n",
        "print(\"Accuracy usando Top-20 features:\")\n",
        "for name in methods:\n",
        "    top20 = rankings[name][:20]\n",
        "    score = cross_val_score(RandomForestClassifier(), X_scaled[:, top20], y, cv=5).mean()\n",
        "    print(f\"{name}: {score:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myjPKcMhwP41"
      },
      "source": [
        "# **Evaluaci√≥n comparativa**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azdYVmEZ9axp"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "print(\"üîç Comparativa de rendimiento (Top-20 caracter√≠sticas):\\n\")\n",
        "\n",
        "for key in ['Inf-FS(u)', 'Inf-FS(s)']:\n",
        "    top20 = rankings[key][:20]\n",
        "    acc = cross_val_score(RandomForestClassifier(), X_scaled[:, top20], y, cv=5).mean()\n",
        "    print(f\"{key} ‚Üí Accuracy promedio (5-CV): {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnwDRrpj9fGs"
      },
      "source": [
        "# **Visualizaci√≥n lado a lado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_MuHMZo9gkm"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(rankings['Inf-FS(u)'][:20], marker='o', label='Inf-FS (u)', color='blue')\n",
        "plt.title(\"Ranking Top-20: Inf-FS No Supervisado\")\n",
        "plt.xlabel(\"Ranking\")\n",
        "plt.ylabel(\"√çndice de Feature\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(rankings['Inf-FS(s)'][:20], marker='o', label='Inf-FS (s)', color='green')\n",
        "plt.title(\"Ranking Top-20: Inf-FS Supervisado\")\n",
        "plt.xlabel(\"Ranking\")\n",
        "plt.ylabel(\"√çndice de Feature\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHN72Yk+WGCfUy5cySipWv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}